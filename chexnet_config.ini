[DEFAULT]
; working directory, one working directory can only have one running job at a time
output_dir = ./experiments/chexnet0

; Verbosity for other stuffs
verbosity = 0

[DATASET]
; Fully Connected model type [multiclass, multibinary]
class_mode = multibinary

; number of train/dev unique patient count,
; test patient count will be (total count - train_patient_count - dev_patient_count), which is 389 by default
train_patient_ratio = 75
dev_patient_ratio = 5

; download this file directly from NIH dropbox
data_entry_file = ./datasets/chexnet_ds/image_data_entry.csv

; class names, you should not modify this
class_names = Atelectasis,Cardiomegaly,Effusion,Infiltration,Mass,Nodule,Pneumonia,Pneumothorax,Consolidation,Edema,Emphysema,Fibrosis,Pleural_Thickening,Hernia

; this variable controlls the class_weight ratio between 0 and 1
; higher value means higher weighting of positive samples
positive_weights_multiply = 1

; if true, mean binary cross-entroy will be weighted by positive counts
; if false, just average the cross-entropy loss of each class
; in both cases, positive/negative sample ratio of each class is considered in the cross-entropy loss
use_class_balancing = true

; if true, use default split, otherwise create a new train/dev/test split
use_default_split = false

; random state used for splitting dataset into train/dev/test sets
split_dataset_random_state = 1
[IMAGE]
; all images should be placed under this dir
image_source_dir = ./datasets/chexnet_ds/images/

; 512 means 512x512 pixels, always use square shaped input
image_dimension = 224

; valid options are 'grayscale', 'rgb' and 'hsv'
color_mode = rgb

[IMAGE-PREPROCESSING]
; normalize
normalize_by_mean_var = true

; color_mode=grayscale
normalize_mean = 0.449

; color_mode=rgb, hsv
normalize_mean_chan1 = 0.485
normalize_mean_chan2 = 0.456
normalize_mean_chan3 = 0.406

; color_mode=grayscale
normalize_stdev = 0.226

; color_mode=rgb, hsv
normalize_stdev_chan1 = 0.229
normalize_stdev_chan2 = 0.224
normalize_stdev_chan3 = 0.225

; samplewise zero-mean, variance normalization. DO NOT set true in conjection with normalize_by_mean_var=true
normalize_samplewise = false

[IMAGE-AUGMENATION]
; Image augmentation

; augmented images will be saved into
aug_verification_path = ./augmentation/verification

; enable augmentation in training set
train_augmentation = true

; enable augmentation in dev set
dev_augmentation = false

; enable augmentation in testing set
test_augmentation = false

random_horz_flip = true
random_vert_flip = true

[MODEL]
; use the following model  (currently support densenet121)
model_name = densenet121

; file path of imagenet pretrained weights, loaded at base_model initialization step
use_base_model_weights = true
base_model_weights_file = ./densenet121_grayscale.h5

; if true, load trained model weights saved in output_dir
; this is typically used for resuming your previous training tasks
; so the use_split_dataset will be automatically set to false
; also, make sure you use the reasonable initial_learning_rate
use_trained_model_weights = true
; if true, use best weights, else use last weights
use_best_weights = false

; note that the best weighting will be saved as best_weights.h5
output_weights_name = weights.h5

; print model summary
show_model_summary = false
[TRAIN]
; number of gpus, 0 means all
gpu = 0

; Resplit dataset (implies starting over)
force_resplit = false

; Print training progress
progress_verbosity = 1

; basic training parameters
epochs = 10
batch_size = 32
initial_learning_rate = 0.001

; steps per epoch for training
; auto or int
; if auto is set, (total samples / batch_size) is used by default.
train_steps = auto

; steps per epoch for validation
; auto or int
; if auto is set, (total samples / batch_size) is used by default.
validation_steps = auto

; patience parameter used for ReduceLROnPlateau callback
; If val_loss doesn't decrease for x epochs, learning rate will be reduced by factor of 10.
patience_reduce_lr = 2
[TEST]
; Print testing progress
progress_verbosity = 2

; Save grad-cam outputs
enable_grad_cam = true

; Output directory of gradcam images
grad_cam_outputdir = ./imgdir

batch_size = 32

test_generator_random_state = 1

; if true, use best_weights.h5, else use weights.h5
use_best_weights = true
